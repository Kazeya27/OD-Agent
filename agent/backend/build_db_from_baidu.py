#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä» baidu.geoã€baidu.odã€baidu.rel æ„å»ºæ•°æ®åº“
æ³¨æ„ï¼šbaidu.od åªå¯¼å…¥ 2024 å¹´ä¹‹åçš„æ•°æ®
"""

import os
import sqlite3
import pandas as pd
from datetime import datetime
from tqdm import tqdm

print("\n" + "="*60)
print("ä»ç™¾åº¦æ•°æ®æ–‡ä»¶æ„å»ºæ•°æ®åº“")
print("="*60)

# é…ç½®
DB_FILE = 'geo_points.db'
DATA_DIR = './agent/data'
BATCH_SIZE = 10000  # æ‰¹é‡æ’å…¥å¤§å°
MIN_YEAR = 2024  # åªå¯¼å…¥æ­¤å¹´ä»½åŠä¹‹åçš„æ•°æ®

# æ–‡ä»¶è·¯å¾„
GEO_FILE = os.path.join(DATA_DIR, 'baidu.geo')
REL_FILE = os.path.join(DATA_DIR, 'baidu.rel')
OD_FILE = os.path.join(DATA_DIR, 'baidu.od')

# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
for file_path in [GEO_FILE, REL_FILE, OD_FILE]:
    if not os.path.exists(file_path):
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        exit(1)

# åˆ é™¤æ—§æ•°æ®åº“
if os.path.exists(DB_FILE):
    confirm = input(f"\nâš ï¸  æ•°æ®åº“ {DB_FILE} å·²å­˜åœ¨ï¼Œæ˜¯å¦åˆ é™¤å¹¶é‡å»º? (y/N): ")
    if confirm.lower() == 'y':
        os.remove(DB_FILE)
        print(f"âœ… å·²åˆ é™¤æ—§æ•°æ®åº“")
    else:
        print("âŒ æ“ä½œå–æ¶ˆ")
        exit(0)

# åˆ›å»ºæ•°æ®åº“è¿æ¥
print(f"\nğŸ“ åˆ›å»ºæ•°æ®åº“: {DB_FILE}")
conn = sqlite3.connect(DB_FILE, timeout=60, isolation_level=None)  # å¢åŠ è¶…æ—¶åˆ°60ç§’
conn.execute("PRAGMA journal_mode=WAL")
conn.execute("PRAGMA synchronous=NORMAL")
conn.execute("PRAGMA cache_size=-64000")  # 64MB cache
conn.execute("PRAGMA busy_timeout=60000")  # 60ç§’å¿™ç­‰å¾…
c = conn.cursor()

# åˆ›å»ºè¡¨ç»“æ„
print("\nğŸ“ åˆ›å»ºè¡¨ç»“æ„...")
c.execute('''
    CREATE TABLE places (
        geo_id INTEGER PRIMARY KEY,
        type TEXT,
        coordinates TEXT,
        name TEXT NOT NULL,
        province TEXT
    )
''')

c.execute('''
    CREATE TABLE relations (
        rel_id INTEGER PRIMARY KEY,
        type TEXT,
        origin_id INTEGER NOT NULL,
        destination_id INTEGER NOT NULL,
        cost REAL
    )
''')

c.execute('''
    CREATE TABLE dyna (
        dyna_id INTEGER PRIMARY KEY,
        type TEXT,
        time TEXT NOT NULL,
        origin_id INTEGER NOT NULL,
        destination_id INTEGER NOT NULL,
        flow REAL
    )
''')

print("âœ… è¡¨ç»“æ„åˆ›å»ºå®Œæˆ")

# 1. å¯¼å…¥åœ°ç†æ•°æ® (places)
print(f"\nğŸ“ å¯¼å…¥åœ°ç†æ•°æ®: {GEO_FILE}")
df_geo = pd.read_csv(GEO_FILE, encoding='utf-8')

# å¡«å……ç¼ºå¤±çš„ province å­—æ®µ
if 'province' not in df_geo.columns:
    df_geo['province'] = ''
else:
    df_geo['province'] = df_geo['province'].fillna('')

# å‡†å¤‡æ•°æ®å¹¶æ’å…¥
records = df_geo[['geo_id', 'type', 'coordinates', 'name', 'province']].values.tolist()
c.executemany('INSERT INTO places VALUES (?,?,?,?,?)', records)
print(f"âœ… å·²å¯¼å…¥ {len(records)} ä¸ªåœ°ç‚¹")

# 2. å¯¼å…¥å…³ç³»æ•°æ® (relations)
print(f"\nğŸ”— å¯¼å…¥å…³ç³»æ•°æ®: {REL_FILE}")
print("   â³ æ­£åœ¨å¤„ç†...")

df_rel = pd.read_csv(REL_FILE, encoding='utf-8')

# å‡†å¤‡æ•°æ®
df_rel['cost'] = df_rel['cost'].fillna(value=0)
records = df_rel[['rel_id', 'type', 'origin_id', 'destination_id', 'cost']].values.tolist()

# æ‰¹é‡æ’å…¥
count = 0
for i in tqdm(range(0, len(records), BATCH_SIZE), desc="å¯¼å…¥å…³ç³»"):
    batch = records[i:i+BATCH_SIZE]
    c.executemany('INSERT INTO relations VALUES (?,?,?,?,?)', batch)
    count += len(batch)

print(f"âœ… å·²å¯¼å…¥ {count} æ¡å…³ç³»è®°å½•")

# 3. å¯¼å…¥ OD æ•°æ® (dyna) - åªå¯¼å…¥ 2024 å¹´åŠä¹‹åçš„æ•°æ®
print(f"\nğŸ“Š å¯¼å…¥ OD æ•°æ®: {OD_FILE}")
print(f"   âš ï¸  åªå¯¼å…¥ {MIN_YEAR} å¹´åŠä¹‹åçš„æ•°æ®")
print("   â³ æ­£åœ¨å¤„ç†...")

# è¯»å– OD æ•°æ®
df_od = pd.read_csv(OD_FILE, encoding='utf-8')

# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºç©º
if len(df_od) == 0:
    print(f"âš ï¸  è­¦å‘Š: {OD_FILE} æ–‡ä»¶ä¸ºç©ºï¼Œè·³è¿‡ OD æ•°æ®å¯¼å…¥")
    count = 0
    skipped = 0
else:
    # æå–å¹´ä»½å¹¶è¿‡æ»¤æ•°æ®
    df_od['year'] = pd.to_datetime(df_od['time']).dt.year
    skipped = len(df_od[df_od['year'] < MIN_YEAR])
    df_od = df_od[df_od['year'] >= MIN_YEAR]
    
    # å‡†å¤‡æ•°æ®
    if 'type' not in df_od.columns:
        df_od['type'] = 'state'
    df_od['flow'] = df_od['flow'].fillna(value=0)
    
    # åˆ é™¤ä¸´æ—¶åˆ—å¹¶å‡†å¤‡æ’å…¥
    df_od = df_od.drop('year', axis=1)
    records = df_od[['dyna_id', 'type', 'time', 'origin_id', 'destination_id', 'flow']].values.tolist()
    
    # æ‰¹é‡æ’å…¥
    count = 0
    for i in tqdm(range(0, len(records), BATCH_SIZE), desc="å¯¼å…¥ODæ•°æ®"):
        batch = records[i:i+BATCH_SIZE]
        c.executemany('INSERT INTO dyna VALUES (?,?,?,?,?,?)', batch)
        count += len(batch)

print(f"âœ… å·²å¯¼å…¥ {count} æ¡ OD è®°å½• (è·³è¿‡ {skipped} æ¡æ—©æœŸæ•°æ®)")

# 4. åˆ›å»ºç´¢å¼•
print("\nğŸ“‘ åˆ›å»ºç´¢å¼•...")
print("   â³ è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´...")

indexes = [
    ('idx_dyna_time', 'dyna', 'time'),
    ('idx_dyna_origin', 'dyna', 'origin_id'),
    ('idx_dyna_destination', 'dyna', 'destination_id'),
    ('idx_dyna_type', 'dyna', 'type'),
    ('idx_relations_origin', 'relations', 'origin_id'),
    ('idx_relations_destination', 'relations', 'destination_id'),
]

for idx_name, table, column in tqdm(indexes, desc="åˆ›å»ºç´¢å¼•"):
    c.execute(f'CREATE INDEX {idx_name} ON {table}({column})')

print("âœ… ç´¢å¼•åˆ›å»ºå®Œæˆ")

# 5. éªŒè¯æ•°æ®
print("\nğŸ” æ•°æ®åº“ç»Ÿè®¡:")
place_count = c.execute('SELECT COUNT(*) FROM places').fetchone()[0]
rel_count = c.execute('SELECT COUNT(*) FROM relations').fetchone()[0]
dyna_count = c.execute('SELECT COUNT(*) FROM dyna').fetchone()[0]

print(f"   åœ°ç‚¹æ•°: {place_count:,}")
print(f"   å…³ç³»æ•°: {rel_count:,}")
print(f"   ODè®°å½•æ•°: {dyna_count:,}")

if dyna_count > 0:
    time_range = c.execute('SELECT MIN(time), MAX(time) FROM dyna').fetchone()
    print(f"   æ—¶é—´èŒƒå›´: {time_range[0]} åˆ° {time_range[1]}")
    
    # æŒ‰ç±»å‹ç»Ÿè®¡
    type_stats = c.execute('SELECT type, COUNT(*) FROM dyna GROUP BY type').fetchall()
    print("\n   æŒ‰ç±»å‹ç»Ÿè®¡:")
    for t, cnt in type_stats:
        print(f"     {t}: {cnt:,}")

# ç¤ºä¾‹æ•°æ®
print("\nğŸ“‹ ç¤ºä¾‹åœ°ç‚¹ (å‰ 5 ä¸ª):")
places = c.execute('SELECT geo_id, name FROM places LIMIT 5').fetchall()
for p in places:
    print(f"   {p[0]}: {p[1]}")

if dyna_count > 0:
    print("\nğŸ“‹ ç¤ºä¾‹ OD è®°å½• (å‰ 5 æ¡):")
    records = c.execute('''
        SELECT d.time, d.origin_id, d.destination_id, d.flow, d.type,
               p1.name as origin_name, p2.name as dest_name
        FROM dyna d
        LEFT JOIN places p1 ON d.origin_id = p1.geo_id
        LEFT JOIN places p2 ON d.destination_id = p2.geo_id
        LIMIT 5
    ''').fetchall()
    for r in records:
        print(f"   {r[0]}: {r[5]} -> {r[6]}, flow={r[3]}, type={r[4]}")

conn.close()

# æœ€ç»ˆä¿¡æ¯
db_size_mb = os.path.getsize(DB_FILE) / (1024 * 1024)
print("\n" + "="*60)
print("âœ… æ•°æ®åº“æ„å»ºå®Œæˆ!")
print("="*60)
print(f"\næ•°æ®åº“ä½ç½®: {os.path.abspath(DB_FILE)}")
print(f"æ•°æ®åº“å¤§å°: {db_size_mb:.2f} MB")

print("\nä¸‹ä¸€æ­¥:")
print("1. é…ç½®ç¯å¢ƒå˜é‡ (.env æ–‡ä»¶):")
print(f"   DB_PATH={os.path.abspath(DB_FILE)}")
print(f"   TABLE_PLACES=places")
print(f"   TABLE_RELATIONS=relations")
print(f"   TABLE_DYNA=dyna")
print("\n2. å¯åŠ¨æœåŠ¡:")
print("   python -m uvicorn app:app --reload")
print("\n3. è®¿é—® API æ–‡æ¡£:")
print("   http://localhost:8000/docs")

print("\n" + "="*60)

